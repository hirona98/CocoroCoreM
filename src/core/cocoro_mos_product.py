"""
CocoroAIå°‚ç”¨MOSProductå®Ÿè£…

MemOSã®MOSProductã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ã€CocoroAIã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç½®æ›ã«ã‚ˆã‚Šã€å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å¤‰æ›´ã›ãšã«å…¨MemOSæ©Ÿèƒ½ã‚’æ—¥æœ¬èªåŒ–
"""

import logging
import json
from typing import Optional, Callable, List, Dict, Any

from memos.mem_os.product import MOSProduct
from memos.memories.textual.item import TextualMemoryItem
from memos.mem_os.utils.format_utils import clean_json_response

from .cocoro_prompts import (
    COCORO_MEMORY_INSTRUCTION,
    COCORO_SUGGESTION_PROMPT_JP,
    # Tree Reorganize Prompts
    REORGANIZE_PROMPT_JP,
    DOC_REORGANIZE_PROMPT_JP,
    LOCAL_SUBCLUSTER_PROMPT_JP,
    PAIRWISE_RELATION_PROMPT_JP,
    INFER_FACT_PROMPT_JP,
    AGGREGATE_PROMPT_JP,
    REDUNDANCY_MERGE_PROMPT_JP,
    MEMORY_RELATION_DETECTOR_PROMPT_JP,
    MEMORY_RELATION_RESOLVER_PROMPT_JP,
    # Memory Scheduler Prompts
    INTENT_RECOGNIZING_PROMPT_JP,
    MEMORY_RERANKING_PROMPT_JP,
    QUERY_KEYWORDS_EXTRACTION_PROMPT_JP,
    # Memory Reader Prompts
    SIMPLE_STRUCT_MEM_READER_PROMPT_JP,
    SIMPLE_STRUCT_DOC_READER_PROMPT_JP,
    SIMPLE_STRUCT_MEM_READER_EXAMPLE_JP,
    # MOS Core Prompts
    COT_DECOMPOSE_PROMPT_JP,
    SYNTHESIS_PROMPT_JP,
    QUERY_REWRITING_PROMPT_JP
)

logger = logging.getLogger(__name__)


class CocoroMOSProduct(MOSProduct):
    """
    CocoroAIå°‚ç”¨MOSProduct
    
    MemOSã®MOSProductã‚’ç¶™æ‰¿ã—ã€å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç½®æ›ã«ã‚ˆã‚Š
    å…¨MemOSæ©Ÿèƒ½ã‚’æ—¥æœ¬èªåŒ–ã—ã¦CocoroAIã‚·ã‚¹ãƒ†ãƒ ã¨çµ±åˆ
    """
    
    def __init__(self, default_config=None, max_user_instances=1, 
                 system_prompt_provider: Optional[Callable[[], Optional[str]]] = None,
                 # LiteLLMçµ±åˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                 litellm_config: Optional[Dict[str, Any]] = None):
        """
        åˆæœŸåŒ–
        
        Args:
            default_config: MemOSãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            max_user_instances: æœ€å¤§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ•°
            system_prompt_provider: CocoroAIã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—é–¢æ•°
            litellm_config: LiteLLMè¨­å®šè¾æ›¸
        """
        # MemOSå…¨ä½“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ—¥æœ¬èªç‰ˆã«ç½®æ›
        self._replace_memos_prompts_with_japanese()
        
        # é€šå¸¸ã®MOSProductåˆæœŸåŒ–ï¼ˆMemOSæ¨™æº–ã®chat_llmãŒä½œæˆã•ã‚Œã‚‹ï¼‰
        super().__init__(default_config=default_config, max_user_instances=max_user_instances)
        
        self.system_prompt_provider = system_prompt_provider
        self._original_chat_llm = None  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼ˆå°†æ¥ã®æ‹¡å¼µã®ãŸã‚ä¿æŒï¼‰
        
        # LiteLLMçµ±åˆï¼ˆæ–¹æ³•1: chat_llmã®ç›´æ¥ç½®ãæ›ãˆï¼‰
        if litellm_config:
            self._setup_litellm(litellm_config)
            # Embeddingã‚‚LiteLLMã§çµ±ä¸€
            self._setup_litellm_embedder(litellm_config)
            # Mem Readerã¨Mem Schedulerã‚‚LiteLLMã§çµ±ä¸€
            self._setup_litellm_mem_reader(litellm_config)
            self._setup_litellm_mem_scheduler(litellm_config)
        
        logger.info(f"CocoroMOSProductåˆæœŸåŒ–å®Œäº†: LiteLLM={'æœ‰åŠ¹' if litellm_config else 'ç„¡åŠ¹'}")
    
    def _replace_memos_prompts_with_japanese(self):
        """
        MemOSã®å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ—¥æœ¬èªç‰ˆã«å‹•çš„ç½®æ›
        
        å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å¤‰æ›´ã›ãšã«ã€å®Ÿè¡Œæ™‚ã«MemOSå†…éƒ¨ã§ä½¿ç”¨ã•ã‚Œã‚‹
        å…¨ã¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ—¥æœ¬èªç‰ˆã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§å®Œå…¨æ—¥æœ¬èªåŒ–ã‚’å®Ÿç¾
        """
        try:
            # Tree Reorganize Promptsï¼ˆè¨˜æ†¶å†ç·¨æˆæ©Ÿèƒ½ï¼‰
            import memos.templates.tree_reorganize_prompts as tree_prompts
            tree_prompts.REORGANIZE_PROMPT = REORGANIZE_PROMPT_JP
            tree_prompts.DOC_REORGANIZE_PROMPT = DOC_REORGANIZE_PROMPT_JP
            tree_prompts.LOCAL_SUBCLUSTER_PROMPT = LOCAL_SUBCLUSTER_PROMPT_JP
            tree_prompts.PAIRWISE_RELATION_PROMPT = PAIRWISE_RELATION_PROMPT_JP
            tree_prompts.INFER_FACT_PROMPT = INFER_FACT_PROMPT_JP
            tree_prompts.AGGREGATE_PROMPT = AGGREGATE_PROMPT_JP
            tree_prompts.REDUNDANCY_MERGE_PROMPT = REDUNDANCY_MERGE_PROMPT_JP
            tree_prompts.MEMORY_RELATION_DETECTOR_PROMPT = MEMORY_RELATION_DETECTOR_PROMPT_JP
            tree_prompts.MEMORY_RELATION_RESOLVER_PROMPT = MEMORY_RELATION_RESOLVER_PROMPT_JP
            
            # Memory Scheduler Promptsï¼ˆè¨˜æ†¶ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼æ©Ÿèƒ½ï¼‰
            import memos.templates.mem_scheduler_prompts as scheduler_prompts
            scheduler_prompts.INTENT_RECOGNIZING_PROMPT = INTENT_RECOGNIZING_PROMPT_JP
            scheduler_prompts.MEMORY_RERANKING_PROMPT = MEMORY_RERANKING_PROMPT_JP
            scheduler_prompts.QUERY_KEYWORDS_EXTRACTION_PROMPT = QUERY_KEYWORDS_EXTRACTION_PROMPT_JP
            
            # Memory Reader Promptsï¼ˆè¨˜æ†¶æŠ½å‡ºæ©Ÿèƒ½ï¼‰
            import memos.templates.mem_reader_prompts as reader_prompts
            reader_prompts.SIMPLE_STRUCT_MEM_READER_PROMPT = SIMPLE_STRUCT_MEM_READER_PROMPT_JP
            reader_prompts.SIMPLE_STRUCT_DOC_READER_PROMPT = SIMPLE_STRUCT_DOC_READER_PROMPT_JP
            reader_prompts.SIMPLE_STRUCT_MEM_READER_EXAMPLE = SIMPLE_STRUCT_MEM_READER_EXAMPLE_JP
            
            # MOS Core Promptsï¼ˆã‚³ã‚¢æ©Ÿèƒ½ï¼‰
            import memos.templates.mos_prompts as mos_prompts
            mos_prompts.COT_DECOMPOSE_PROMPT = COT_DECOMPOSE_PROMPT_JP
            mos_prompts.SYNTHESIS_PROMPT = SYNTHESIS_PROMPT_JP
            mos_prompts.QUERY_REWRITING_PROMPT = QUERY_REWRITING_PROMPT_JP
            
            # Schedulerç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°ã‚‚æ›´æ–°
            if hasattr(scheduler_prompts, 'PROMPT_MAPPING'):
                scheduler_prompts.PROMPT_MAPPING.update({
                    "intent_recognizing": INTENT_RECOGNIZING_PROMPT_JP,
                    "memory_reranking": MEMORY_RERANKING_PROMPT_JP,
                    "query_keywords_extraction": QUERY_KEYWORDS_EXTRACTION_PROMPT_JP,
                })
                
            logger.info("ğŸŒ MemOSå…¨æ©Ÿèƒ½ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ—¥æœ¬èªç‰ˆã«ç½®æ›å®Œäº†")
            
        except ImportError as e:
            logger.warning(f"MemOSãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
        except Exception as e:
            logger.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç½®æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}", exc_info=True)
    
    def _ensure_api_key(self, config: Dict[str, Any], key_name: str = 'api_key', component_name: str = '') -> None:
        """APIã‚­ãƒ¼ãŒç©ºã®å ´åˆã¯ãƒ€ãƒŸãƒ¼å€¤ã‚’è¨­å®šã™ã‚‹å…±é€šå‡¦ç†ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMç”¨ï¼‰"""
        if key_name not in config or not config[key_name]:
            config[key_name] = 'dummy-api-key'
            model_name = config.get('model' if key_name == 'api_key' else 'embedding_model', 'unknown')
            logger.info(f"{component_name}APIã‚­ãƒ¼ãŒç©ºã®ãŸã‚ã€ãƒ€ãƒŸãƒ¼å€¤ã‚’è¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«LLMç”¨ï¼‰: model={model_name}")
    
    def _setup_litellm(self, config: Dict[str, Any]):
        """LiteLLMã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯ä¾‹å¤–ã‚’å†ç™ºç”Ÿï¼‰"""
        try:
            # å…ƒã®chat_llmã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆå°†æ¥ã®æ‹¡å¼µã®ãŸã‚ï¼‰
            self._original_chat_llm = self.chat_llm
            
            # LiteLLMWrapper import
            from .litellm_wrapper import LiteLLMConfig, LiteLLMWrapper
            
            # LiteLLMConfigä½œæˆï¼ˆè¨­å®šå¿…é ˆï¼‰
            if 'model' not in config or not config['model']:
                raise ValueError("âŒ LiteLLMè¨­å®šã«modelãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            self._ensure_api_key(config, 'api_key', '')
                
            litellm_config = LiteLLMConfig(
                model_name=config['model'],
                api_key=config['api_key'],
                max_tokens=config.get('max_tokens', 1024),
                extra_config=config.get('extra_config', {})
            )
            
            # chat_llmã‚’LiteLLMWrapperã«ç½®ãæ›ãˆ
            self.chat_llm = LiteLLMWrapper(litellm_config)
            
            logger.info(f"âœ… LiteLLMçµ±åˆå®Œäº†: {litellm_config.model_name_or_path}")
            
        except Exception as e:
            # è©³ç´°ã‚¨ãƒ©ãƒ¼å‡ºåŠ›
            logger.error(f"âŒ LiteLLMã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å¤±æ•—:")
            logger.error(f"   ãƒ¢ãƒ‡ãƒ«: {config.get('model', 'N/A')}")
            logger.error(f"   ã‚¨ãƒ©ãƒ¼: {str(e)}")
            logger.error(f"   è¨­å®šå†…å®¹: {config}")
            
            # ã‚¨ãƒ©ãƒ¼ã‚’å†ç™ºç”Ÿï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ãªã„ï¼‰
            raise RuntimeError(f"LiteLLMã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def _setup_litellm_embedder(self, config: Dict[str, Any]):
        """LiteLLM Embedder ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆã™ã¹ã¦ã®MemCubeã®embedderã‚’ç½®ãæ›ãˆï¼‰"""
        try:
            from .litellm_embedder import LiteLLMEmbedder
            from .litellm_wrapper import LiteLLMConfig
            
            # Embeddingç”¨LiteLLMConfigä½œæˆï¼ˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ç”¨ã€è¨­å®šå¿…é ˆï¼‰
            if 'embedding_model' not in config or not config['embedding_model']:
                raise ValueError("âŒ LiteLLMè¨­å®šã«embedding_modelãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            self._ensure_api_key(config, 'embedding_api_key', 'åŸ‹ã‚è¾¼ã¿')
                
            embedder_config = {
                "model_name_or_path": config['embedding_model'],
                "api_key": config['embedding_api_key'],
                "extra_config": {}
            }
            
            # LiteLLMEmbedderä½œæˆã—ã¦ä¿å­˜ï¼ˆMemCubeä½œæˆå¾Œã«ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
            self._litellm_embedder = LiteLLMEmbedder(embedder_config)
            self._litellm_embedder_config = embedder_config
            
            # æ—¢å­˜ã®MemCubeã®embedderã‚’ç½®ãæ›ãˆ
            replaced_count = 0
            for cube_id, mem_cube in self.mem_cubes.items():
                if hasattr(mem_cube, 'text_mem') and mem_cube.text_mem is not None:
                    # TreeTextMemoryã®embedderã‚’ç½®ãæ›ãˆ
                    original_embedder = mem_cube.text_mem.embedder
                    mem_cube.text_mem.embedder = self._litellm_embedder
                    
                    # MemoryManagerã®embedderã‚‚ç½®ãæ›ãˆï¼ˆä¸€è²«æ€§ã®ãŸã‚ï¼‰
                    if hasattr(mem_cube.text_mem, 'memory_manager'):
                        mem_cube.text_mem.memory_manager.embedder = self._litellm_embedder
                    
                    replaced_count += 1
                    logger.debug(f"MemCube {cube_id} ã®embedderã‚’LiteLLMã«ç½®ãæ›ãˆ")
            
            logger.info(f"ğŸ”„ LiteLLM Embedderçµ±åˆå®Œäº†: {replaced_count}å€‹ã®MemCubeã§ç½®ãæ›ãˆå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ LiteLLM Embedderçµ±åˆå¤±æ•—: {e}")
            # Embedderç½®ãæ›ãˆå¤±æ•—ã¯éè‡´å‘½çš„ï¼ˆLLMã¯å‹•ä½œã™ã‚‹ï¼‰
            logger.warning("Embeddingæ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ãŒã€LLMæ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¾ã™")
    
    def _setup_litellm_mem_reader(self, config: Dict[str, Any]):
        """LiteLLM Mem Reader ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆmem_reader.llmã¨embedderã‚’ç½®ãæ›ãˆï¼‰"""
        try:
            from .litellm_wrapper import LiteLLMConfig, LiteLLMWrapper
            from .litellm_embedder import LiteLLMEmbedder
            
            # Mem Readerç”¨LiteLLMConfigä½œæˆï¼ˆLLMç”¨ã€è¨­å®šå¿…é ˆï¼‰
            if 'model' not in config or not config['model']:
                raise ValueError("âŒ LiteLLMè¨­å®šã«modelãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            self._ensure_api_key(config, 'api_key', 'Mem Readerç”¨')
                
            mem_reader_config = LiteLLMConfig(
                model_name=config['model'],
                api_key=config['api_key'],
                max_tokens=config.get('max_tokens', 2048),  # mem_readerç”¨ã¯å¤šã‚ã«è¨­å®š
                extra_config=config.get('extra_config', {})
            )
            
            # mem_reader.llmã¨embedderã‚’ç½®ãæ›ãˆ
            if hasattr(self, 'mem_reader') and self.mem_reader is not None:
                replaced_count = 0
                
                # 1. LLMã®ç½®ãæ›ãˆ
                if hasattr(self.mem_reader, 'llm'):
                    original_llm = self.mem_reader.llm
                    self.mem_reader.llm = LiteLLMWrapper(mem_reader_config)
                    replaced_count += 1
                    logger.debug("Mem Reader LLM ã‚’LiteLLMã«ç½®ãæ›ãˆ")
                
                # 2. é‡è¦ï¼šEmbedderã®ç½®ãæ›ãˆï¼ˆã‚¨ãƒ©ãƒ¼ã®æ ¹æœ¬åŸå› ï¼‰
                if hasattr(self.mem_reader, 'embedder') and self.mem_reader.embedder is not None:
                    # LiteLLMEmbedderãŒæº–å‚™ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä½¿ç”¨
                    if hasattr(self, '_litellm_embedder') and self._litellm_embedder is not None:
                        original_embedder = self.mem_reader.embedder
                        self.mem_reader.embedder = self._litellm_embedder
                        replaced_count += 1
                        logger.debug("Mem Reader Embedder ã‚’LiteLLMã«ç½®ãæ›ãˆ")
                    else:
                        logger.warning("LiteLLMEmbedder ãŒæº–å‚™ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                
                logger.info(f"ğŸ”„ Mem Reader LLMãƒ»Embedder ã‚’LiteLLMã«ç½®ãæ›ãˆå®Œäº†: {replaced_count}å€‹")
            else:
                logger.warning("mem_reader ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
        except Exception as e:
            logger.error(f"âŒ Mem Reader LiteLLMçµ±åˆå¤±æ•—: {e}")
            # mem_readerç½®ãæ›ãˆå¤±æ•—ã¯éè‡´å‘½çš„
            logger.warning("Mem Readeræ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ãŒã€ä»–ã®æ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¾ã™")
    
    def _setup_litellm_mem_scheduler(self, config: Dict[str, Any]):
        """LiteLLM Mem Scheduler ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆå…¨éšå±¤ã®_process_llmã‚’å†å¸°çš„ã«ç½®ãæ›ãˆï¼‰"""
        try:
            from .litellm_wrapper import LiteLLMConfig, LiteLLMWrapper
            
            # Mem Schedulerç”¨LiteLLMConfigä½œæˆï¼ˆLLMç”¨ã€è¨­å®šå¿…é ˆï¼‰
            if 'model' not in config or not config['model']:
                raise ValueError("âŒ LiteLLMè¨­å®šã«modelãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            self._ensure_api_key(config, 'api_key', 'Mem Schedulerç”¨')
                
            mem_scheduler_config = LiteLLMConfig(
                model_name=config['model'],
                api_key=config['api_key'],
                max_tokens=config.get('max_tokens', 1024),
                extra_config=config.get('extra_config', {})
            )
            
            # LiteLLMWrapperã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆï¼ˆä½¿ã„å›ã—ç”¨ï¼‰
            litellm_wrapper = LiteLLMWrapper(mem_scheduler_config)
            
            # mem_schedulerå†…ã®å…¨LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å†å¸°çš„ã«ç½®ãæ›ãˆ
            if hasattr(self, '_mem_scheduler') and self._mem_scheduler is not None:
                replaced_count = 0
                
                # 1. ç›´æ¥_process_llmå±æ€§ã‚’æŒã¤å ´åˆã®å¯¾å¿œ
                if hasattr(self._mem_scheduler, '_process_llm'):
                    self._mem_scheduler._process_llm = litellm_wrapper
                    replaced_count += 1
                    logger.debug("Scheduler ã®_process_llmã‚’ç›´æ¥ç½®ãæ›ãˆ")
                
                # 2. moduleså†…ã®LLMã‚’ç½®ãæ›ãˆ
                if hasattr(self._mem_scheduler, 'modules'):
                    for module_name, module in self._mem_scheduler.modules.items():
                        if hasattr(module, '_process_llm'):
                            module._process_llm = litellm_wrapper
                            replaced_count += 1
                            logger.debug(f"Scheduler module {module_name} ã®_process_llmã‚’ç½®ãæ›ãˆ")
                
                # 3. é‡è¦ï¼šmonitorå†…ã®LLMã‚’ç½®ãæ›ãˆï¼ˆã‚¨ãƒ©ãƒ¼ã®æ ¹æœ¬åŸå› ï¼‰
                if hasattr(self._mem_scheduler, 'monitor') and self._mem_scheduler.monitor is not None:
                    if hasattr(self._mem_scheduler.monitor, '_process_llm'):
                        self._mem_scheduler.monitor._process_llm = litellm_wrapper
                        replaced_count += 1
                        logger.debug("Scheduler monitor ã®_process_llmã‚’ç½®ãæ›ãˆ")
                
                # 4. å†å¸°çš„ã«å…¨å±æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå¿µã®ãŸã‚ï¼‰
                replaced_count += self._replace_llm_recursive(self._mem_scheduler, litellm_wrapper, 'scheduler')
                
                logger.info(f"ğŸ”„ Mem Scheduler LLM ã‚’LiteLLMã«ç½®ãæ›ãˆå®Œäº†: {replaced_count}å€‹ã®LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹")
            else:
                logger.warning("_mem_scheduler ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
        except Exception as e:
            logger.error(f"âŒ Mem Scheduler LiteLLMçµ±åˆå¤±æ•—: {e}")
            # mem_schedulerç½®ãæ›ãˆå¤±æ•—ã¯éè‡´å‘½çš„
            logger.warning("Mem Scheduleræ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ãŒã€ä»–ã®æ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¾ã™")
    
    def _replace_llm_recursive(self, obj, litellm_wrapper, parent_name: str, max_depth: int = 3) -> int:
        """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã®_process_llmã‚’å†å¸°çš„ã«ç½®ãæ›ãˆ"""
        if max_depth <= 0:
            return 0
            
        replaced_count = 0
        try:
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å…¨å±æ€§ã‚’ãƒã‚§ãƒƒã‚¯
            for attr_name in dir(obj):
                if attr_name.startswith('_') and attr_name != '_process_llm':
                    continue
                    
                try:
                    attr_value = getattr(obj, attr_name)
                    
                    # _process_llmå±æ€§ã‚’ç™ºè¦‹ã—ãŸå ´åˆã¯ç½®ãæ›ãˆ
                    if attr_name == '_process_llm' and attr_value is not None:
                        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆmemos.llms.openaiï¼‰ã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯
                        if hasattr(attr_value, 'generate') and hasattr(attr_value, 'client'):
                            setattr(obj, attr_name, litellm_wrapper)
                            replaced_count += 1
                            logger.debug(f"å†å¸°çš„ç½®ãæ›ãˆ: {parent_name}.{attr_name}")
                    
                    # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå‹ã®å±æ€§ãŒã‚ã‚Œã°å†å¸°çš„ã«ãƒã‚§ãƒƒã‚¯
                    elif (hasattr(attr_value, '__dict__') and 
                          not isinstance(attr_value, (str, int, float, bool, list, dict, tuple)) and
                          not callable(attr_value)):
                        replaced_count += self._replace_llm_recursive(
                            attr_value, litellm_wrapper, 
                            f"{parent_name}.{attr_name}", max_depth - 1
                        )
                        
                except (AttributeError, TypeError):
                    continue
                    
        except Exception as e:
            logger.debug(f"å†å¸°çš„LLMç½®ãæ›ãˆä¸­ã®è»½å¾®ãªã‚¨ãƒ©ãƒ¼: {e}")
            
        return replaced_count
    
    def register_mem_cube(self, *args, **kwargs):
        """MemCubeç™»éŒ²ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ã¦ã€ç™»éŒ²å¾Œã«LiteLLMEmbedderã«ç½®ãæ›ãˆ"""
        # è¦ªã‚¯ãƒ©ã‚¹ã®æ¨™æº–ç™»éŒ²å‡¦ç†ã‚’å®Ÿè¡Œ
        result = super().register_mem_cube(*args, **kwargs)
        
        # LiteLLMEmbedderãŒæº–å‚™ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯æ–°ã—ã„MemCubeã®embedderã‚’ç½®ãæ›ãˆ
        if hasattr(self, '_litellm_embedder') and self._litellm_embedder is not None:
            self._replace_new_memcube_embedder()
        
        return result
    
    def _replace_new_memcube_embedder(self):
        """æ–°ã—ãä½œæˆã•ã‚ŒãŸMemCubeã®embedderã‚’LiteLLMã«ç½®ãæ›ãˆ"""
        try:
            replaced_count = 0
            for cube_id, mem_cube in self.mem_cubes.items():
                if hasattr(mem_cube, 'text_mem') and mem_cube.text_mem is not None:
                    # UniversalAPIEmbedderã‹ã©ã†ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆMemOSã®æ¨™æº–embedderï¼‰
                    current_embedder = mem_cube.text_mem.embedder
                    embedder_type = type(current_embedder).__name__
                    
                    # UniversalAPIEmbedderã®å ´åˆã®ã¿ç½®ãæ›ãˆ
                    if embedder_type == 'UniversalAPIEmbedder':
                        # TreeTextMemoryã®embedderã‚’ç½®ãæ›ãˆ
                        mem_cube.text_mem.embedder = self._litellm_embedder
                        
                        # MemoryManagerã®embedderã‚‚ç½®ãæ›ãˆï¼ˆä¸€è²«æ€§ã®ãŸã‚ï¼‰
                        if hasattr(mem_cube.text_mem, 'memory_manager'):
                            mem_cube.text_mem.memory_manager.embedder = self._litellm_embedder
                        
                        replaced_count += 1
                        logger.info(f"ğŸ”„ æ–°è¦MemCube {cube_id} ã®embedderã‚’LiteLLMã«ç½®ãæ›ãˆå®Œäº† ({embedder_type} â†’ LiteLLMEmbedder)")
                    else:
                        logger.debug(f"MemCube {cube_id} ã®embedderã¯æ—¢ã«LiteLLM ({embedder_type})")
            
            if replaced_count > 0:
                logger.info(f"âœ… æ–°è¦MemCube embedderç½®ãæ›ãˆå®Œäº†: {replaced_count}å€‹")
                
        except Exception as e:
            logger.error(f"âŒ æ–°è¦MemCube embedderç½®ãæ›ãˆå¤±æ•—: {e}")
            logger.warning("æ–°ã—ã„MemCubeã§Embeddingæ©Ÿèƒ½ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ãŒã€LLMæ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¾ã™")
    
    def _build_enhance_system_prompt(
        self, user_id: str, memories_all: List[TextualMemoryItem]
    ) -> str:
        """
        CocoroAIå°‚ç”¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        
        CocoroAIã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + è¨˜æ†¶æ©Ÿèƒ½æŒ‡ç¤º + ãƒ¡ãƒ¢ãƒªæƒ…å ±ã‚’çµ±åˆ
        """
        # CocoroAIã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        cocoro_prompt = None
        if self.system_prompt_provider:
            try:
                cocoro_prompt = self.system_prompt_provider()
                logger.info(f"CocoroAIã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—æˆåŠŸ: {bool(cocoro_prompt)}")
            except Exception as e:
                logger.error(f"CocoroAIã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: CocoroAIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå–å¾—ã§ããªã„å ´åˆã¯å…ƒã®MemOSãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
        if not cocoro_prompt:
            logger.warning("CocoroAIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœªè¨­å®šã€MemOSãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨")
            return super()._build_enhance_system_prompt(user_id, memories_all)
        
        # ãƒ¡ãƒ¢ãƒªæƒ…å ±ã®è¿½åŠ å‡¦ç†ï¼ˆMemOSã®æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¾“ã†ï¼‰
        if memories_all:
            personal_memory_context = "\n\n## Available ID and PersonalMemory Memories:\n"
            outer_memory_context = "\n\n## Available ID and OuterMemory Memories:\n"
            
            personal_memory_count = 0
            outer_memory_count = 0
            
            for i, memory in enumerate(memories_all, 1):
                # ãƒ¡ãƒ¢ãƒªIDã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ï¼ˆMemOSã¨åŒã˜å½¢å¼ï¼‰
                memory_id = (
                    f"{memory.id.split('-')[0]}" if hasattr(memory, "id") else f"mem_{i}"
                )
                memory_content = (
                    memory.memory[:500] if hasattr(memory, "memory") else str(memory)
                )
                
                # ãƒ¡ãƒ¢ãƒªã‚¿ã‚¤ãƒ—åˆ¥ã«åˆ†é¡
                if memory.metadata.memory_type != "OuterMemory":
                    personal_memory_context += f"{memory_id}: {memory_content}\n"
                    personal_memory_count += 1
                else:
                    # OuterMemoryã®å ´åˆã¯æ”¹è¡Œã‚’é™¤å»
                    memory_content = memory_content.replace("\n", " ")
                    outer_memory_context += f"{memory_id}: {memory_content}\n"
                    outer_memory_count += 1
            
            # è¨˜æ†¶ãŒã‚ã‚‹å ´åˆã¯ã€CocoroAIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + è¨˜æ†¶æ©Ÿèƒ½æŒ‡ç¤º + ãƒ¡ãƒ¢ãƒªæƒ…å ±
            memory_sections = ""
            if personal_memory_count > 0:
                memory_sections += personal_memory_context
            if outer_memory_count > 0:
                memory_sections += outer_memory_context
            
            result_prompt = cocoro_prompt + COCORO_MEMORY_INSTRUCTION + memory_sections
            logger.info(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰å®Œäº†: CocoroAI + è¨˜æ†¶æŒ‡ç¤º + ãƒ¡ãƒ¢ãƒªæƒ…å ± (PersonalMemory: {personal_memory_count}, OuterMemory: {outer_memory_count})")
            return result_prompt
        
        # ãƒ¡ãƒ¢ãƒªãŒãªã„å ´åˆã¯CocoroAIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ï¼ˆè¨˜æ†¶æŒ‡ç¤ºä¸è¦ï¼‰
        logger.info("ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰å®Œäº†: CocoroAIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿")
        return cocoro_prompt
    
    def get_suggestion_query(self, user_id: str, language: str = "ja") -> List[str]:
        """
        CocoroAIå°‚ç”¨ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚¯ã‚¨ãƒªç”Ÿæˆï¼ˆæ—¥æœ¬èªå°‚ç”¨ï¼‰
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            language: è¨€èªè¨­å®šï¼ˆæ—¥æœ¬èªå›ºå®šï¼‰
            
        Returns:
            List[str]: ã‚µã‚¸ã‚§ã‚¹ãƒãƒ§ãƒ³ã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
        """
        # æœ€è¿‘ã®è¨˜æ†¶ã‚’å–å¾—
        text_mem_result = super().search("my recently memories", user_id=user_id, top_k=3)[
            "text_mem"
        ]
        if text_mem_result:
            memories = "\n".join([m.memory[:200] for m in text_mem_result[0]["memories"]])
        else:
            memories = ""
        
        # æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚¯ã‚¨ãƒªç”Ÿæˆ
        message_list = [{"role": "system", "content": COCORO_SUGGESTION_PROMPT_JP.format(memories=memories)}]
        response = self.chat_llm.generate(message_list)
        clean_response = clean_json_response(response)
        response_json = json.loads(clean_response)
        return response_json["query"]